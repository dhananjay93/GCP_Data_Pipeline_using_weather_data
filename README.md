# ğŸŒ¦ Weather Data Pipeline on GCP  
**Composer â†’ BigQuery â†’ Colab â†’ Looker Studio**

## ğŸ“Œ Objective  
This project builds a fully automated data pipeline to **fetch and visualize live weather data** (temperature, humidity, conditions) for major Indian cities using the **Google Cloud Platform (GCP)** ecosystem.

The pipeline:  
- â± Calls **OpenWeather API** hourly  
- âš™ï¸ Orchestrates ingestion with **Cloud Composer (Airflow)**  
- ğŸ—„ Stores curated records in **BigQuery** (partitioned & clustered for cost efficiency)  
- â˜ Archives raw JSON into **Cloud Storage** (optional, for audits/backfills)  
- ğŸ“Š Explores insights in **Google Colab**  
- ğŸ“ˆ Visualizes results in **Looker Studio** dashboards  

---

## ğŸ— Architecture  

![Weather Data Pipeline Architecture](<img width="1326" height="619" alt="image" src="https://github.com/user-attachments/assets/b411a0ad-c23c-4e04-bc91-b157bd1dd65a" />
)

---

## ğŸ”§ Components  
- ğŸŒ **OpenWeather API** â†’ Source of live weather data (15 Indian cities)  
- ğŸ”‘ **Secret Manager / Env Vars** â†’ Secure API key storage  
- â˜ **Cloud Composer (Airflow)** â†’ Orchestration of ingestion + checks  
- ğŸ—„ **Cloud Storage (GCS)** â†’ Raw JSON archive (`gs://weather-raw-archive/`)  
- ğŸ“Š **BigQuery** â†’ Analytical warehouse  
  - Partitioned by `DATE(ts_utc)`  
  - Clustered by `city`  
  - Unique key â†’ `(city, source_dt_utc)`  
- ğŸ“ˆ **Looker Studio** â†’ Interactive visualization dashboards  
- ğŸ **Google Colab** â†’ Exploratory analysis + insights generation  

---

## ğŸš€ Setup Steps  

### 1. OpenWeather API  
- Sign up: [OpenWeather API](https://openweathermap.org/api)  
- Generate and copy your API key  

### 2. Cloud Composer  
- Create a Composer environment in the same region as BigQuery dataset  
- Add environment variables:  
  ```bash
  OPENWEATHER_API_KEY=<your_api_key>
  RAW_BUCKET=weather-raw-archive
  ```

### 3. BigQuery  
- Create dataset: `airflow_bq_looker_project`  
- The DAG will create table **`openweather_15_cities_v2`**  
  - Partitioned + clustered by `city`  

### 4. Cloud Storage  
- Create bucket: `weather-raw-archive`  
- Raw JSON payloads stored as:  
  ```
  gs://weather-raw-archive/openweather/YYYY/MM/DD/HH/payload.json
  ```

### 5. Deploy DAG  
- Save DAG as `openweather_to_bq.py`  
- Upload to Composerâ€™s DAGs bucket  
- Trigger DAG from Airflow UI  

### 6. Validate in BigQuery  
Run test query:  
```sql
SELECT city, temp, ts_utc
FROM `airflowbigqueryproject.airflow_bq_looker_project.openweather_15_cities_v2`
ORDER BY ts_utc DESC
LIMIT 20;
```

### 7. Looker Studio  
- Connect Looker Studio to BigQuery  
- Build dashboards for:  
  - Temperature trends per city  
  - Humidity & pressure comparisons  
  - Latest snapshot across all cities  

### 8. Google Colab  
- Connect Colab to BigQuery  
- Generate exploratory insights  

---

## ğŸ”’ Reliability & Security  
- **Secrets** â†’ API key stored in Env Vars  
- **Idempotency** â†’ Stage + MERGE pattern prevents duplicates  
- **Partitioning & Clustering** â†’ Optimizes query cost & performance  
- **Monitoring** â†’  
  - Row count check (â‰¥ 80% of cities)  
  - Temperature sanity check (`-20Â°C < temp < 55Â°C`)  

---

## ğŸŒ± Future Enhancements  
- Add a **dbt / Python transformation layer**  
- Enrich with other APIs (AQI, rainfall, weather alerts)  

---

## ğŸ“‚ Project Structure  
```
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ openweather_to_bq.py    # Airflow DAG for ingestion
â”œâ”€â”€ documentation/              # Notion Documentation
â”œâ”€â”€ colab/                      # Colab notebooks for analysis
â””â”€â”€ README.md                   # Project documentation
```
